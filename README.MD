# Deep Learning Indaba Practicals 2022
  
## The Practicals 
| Topic ğŸ’¥ | Description ğŸ“˜ | Colab ğŸ‘©â€ğŸ’» |
|---------------|----------------------------------------------------------|----------------------------------------------------------------------------------------------------------|
[Introduction to ML using JAX](https://github.com/deep-learning-indaba/indaba-pracs-2022/blob/main/Introduction_to_ML_using_JAX.ipynb) | In this tutorial, we will learn about JAX, a new machine learning framework that has taken deep learning research by storm! JAX is praised for its speed, and we will learn how to achieve these speedups, using core concepts in JAX, such as automatic differentiation (`grad`), parallelization (`pmap`), vectorization (`vmap`), just-in-time compilation (`jit`), and more. We will then use what we have learned to implement Linear Regression effectively while learning some of the fundamentals of optimization. | [Link](https://colab.research.google.com/github/deep-learning-indaba/indaba-pracs-2022/blob/main/Introduction_to_ML_using_JAX.ipynb) | 

This repository contains the practical notebooks for the Deep Learning Indaba
2022, held at SUPâ€™COM University in Tunis, Tunisia.

See [www.deeplearningindaba.com](http://www.deeplearningindaba.com) for more details.
